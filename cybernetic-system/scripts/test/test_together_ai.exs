#!/usr/bin/env elixir

# Test script for Together AI provider integration

IO.puts("ðŸš€ Testing Together AI Provider Integration")
IO.puts("=" |> String.duplicate(45))

# Check if API key is available
api_key = System.get_env("TOGETHER_API_KEY")

if api_key do
  IO.puts("âœ… Together AI API key found")
  
  # Test provider capabilities
  IO.puts("\nðŸ“Š Provider Capabilities:")
  caps = Cybernetic.VSM.System4.Providers.Together.capabilities()
  IO.puts("  Modes: #{inspect(caps.modes)}")
  IO.puts("  Strengths: #{inspect(caps.strengths)}")
  IO.puts("  Max Tokens: #{caps.max_tokens}")
  IO.puts("  Context Window: #{caps.context_window} (128k!)")
  
  # Test health check
  IO.puts("\nðŸ¥ Health Check:")
  case Cybernetic.VSM.System4.Providers.Together.health_check() do
    :ok -> IO.puts("  âœ… Together AI is healthy")
    {:error, reason} -> IO.puts("  âŒ Health check failed: #{inspect(reason)}")
  end
  
  # Test generation
  IO.puts("\nðŸ¤– Testing Generation:")
  case Cybernetic.VSM.System4.Providers.Together.generate(
    "Explain the benefits of using multiple open-source AI models in production. Answer in 2 sentences.",
    model: "mistralai/Mixtral-8x7B-Instruct-v0.1",
    max_tokens: 100
  ) do
    {:ok, result} ->
      IO.puts("  âœ… Generation successful")
      IO.puts("  Response: #{String.slice(result.text, 0, 200)}...")
      IO.puts("  Tokens: #{result.tokens.input} in, #{result.tokens.output} out")
      IO.puts("  Cost: $#{Float.round(result.usage.cost_usd, 5)}")
      
    {:error, reason} ->
      IO.puts("  âŒ Generation failed: #{inspect(reason)}")
  end
  
else
  IO.puts("âš ï¸  TOGETHER_API_KEY not set")
  IO.puts("\nTo test Together AI, set your API key:")
  IO.puts("  export TOGETHER_API_KEY='your-api-key-here'")
  IO.puts("\nYou can get a free API key at: https://api.together.xyz")
end

IO.puts("\nðŸ“ Together AI Provider Integration Summary")
IO.puts("-" |> String.duplicate(45))

IO.puts("\nðŸŽ¯ Key Features:")
IO.puts("â€¢ Access to 100+ open-source models")
IO.puts("â€¢ Llama 3.1 70B with 128k context")
IO.puts("â€¢ Mixtral for fast inference")
IO.puts("â€¢ Code-optimized models available")
IO.puts("â€¢ Competitive pricing (~$0.88/1M tokens)")

IO.puts("\nðŸ”„ S4 Routing Integration:")
IO.puts("â€¢ Code Generation: OpenAI â†’ Together â†’ Anthropic")
IO.puts("â€¢ Fast Analysis: Together â†’ Anthropic â†’ OpenAI")
IO.puts("â€¢ Predictions: Together â†’ Anthropic â†’ OpenAI")
IO.puts("â€¢ Classifications: Together â†’ OpenAI â†’ Ollama")

IO.puts("\nðŸ“Š Provider Comparison:")
provider_comparison = """
| Provider   | Strengths              | Context | Cost/1M   |
|------------|------------------------|---------|-----------|
| Anthropic  | Deep reasoning         | 200k    | $3-15     |
| OpenAI     | Code generation        | 128k    | $2-10     |
| Together   | Speed + Open models    | 128k    | $0.60-0.88|
| Ollama     | Privacy + Zero cost    | 8k      | $0.00     |
"""
IO.puts(provider_comparison)

IO.puts("\nâœ… Together AI successfully integrated into S4 Multi-Provider Hub!")